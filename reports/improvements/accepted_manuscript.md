Pragmadic: An AI-Driven Platform for Enhancing Digital Nomad Onboarding and Local Integration in Malaysia
Loh Yet Marn, Matthew1, a) and Jayahkudy, Usha1, b)
Author Affiliations
1INTI International College Penang, 1-Z, Lebuh Bukit Jambul, Bukit Jambul, 11900, Bayan Lepas, Pulau Pinang, Malaysia

Author Emails
a) Corresponding author: matthewloh256@gmail.com
b) usha.jayahkudy@newinti.edu.my
Abstract. Pragmadic is a web-based platform designed to enhance the onboarding experience of digital nomads (DNs) in Malaysia, particularly applicants of the DE Rantau Nomad Pass visa program. It addresses the challenge of fragmented information and the lack of a centralized resource hub, which hinders seamless integration and access to local opportunities. Pragmadic leverages Retrieval-Augmented Generation (RAG) and large language models (LLMs) to aggregate and deliver real-time, personalized information, streamlining the onboarding process for DNs and supporting coworking space hub owners. Initially implemented in Penang, the platform follows a prototyping methodology for iterative development. The technology stack includes Next.js for the frontend, Supabase for the backend, and AI models from OpenAI, Gemini, and Anthropic. Rigorous functional and non-functional testing, including black-box, integration, and security testing, ensures robust performance and compatibility. The Prototyping model was chosen for its adaptability to evolving stakeholder needs and the dynamic LLM environment. Expected outcomes include reducing information barriers for DNs, fostering local ecosystem connections, and enhancing business visibility within the DE Rantau Hub Partner program through LLM-driven analytics. Pragmadic aims to provide a centralized, intelligent support system that will significantly improve the digital nomad experience in Malaysia.
INTRODUCTION
The rise of digital nomadism represents a fundamental transformation in work culture and the social contract, enabling professionals to operate independent of location. This trend presents significant economic opportunities for host countries, attracting highly skilled and valued talent while fostering digital economic innovation. However, it also challenges sustainable development across broader social and governance contexts. Malaysia, proactively recognizing this potential, launched the DE Rantau program to establish itself as the preferred digital nomad (DN) hub within ASEAN, providing more permissive visa policies than global competitors [1, 2]. Early statistics from 2024 indicate growing interest, with diverse nationalities participating and contributing significantly to the local economy [3].
However, despite increasing concerted investments in the initiative, prospective and current DE Rantau DNs face considerable hurdles. Key challenges include navigating decentralized, fragmented information landscapes when researching visa requirements, accommodation, local regulations (especially taxation), and cultural nuances. Existing platforms, or a lack thereof, lack centralized, personalized, and up-to-date resources, hindering seamless integration and preventing DNs from fully capitalizing on local opportunities, particularly outside major hubs like Kuala Lumpur [4].
To address these gaps, particularly within the context of Penang, an emerging DN destination in Malaysia, this paper introduces the Pragmadic platform, leveraging emerging full-stack frameworks and AI technologies. Pragmadic utilizes Retrieval-Augmented Generation (RAG) for large language models (LLMs) to create a more effective answer engine. The implementation provides DNs with tailored, contextually relevant information from curated DE Rantau program documents. Beyond the RAG core, the platform facilitates onboarding and integration through interactive mapping, event discovery, community networking features, and AI-driven analytics tools for local DE Rantau Hub partners to guide decisions.
The overall goal is to present Pragmadic’s position from the standpoint of sustainable development and intelligent computing, employing emergent web and AI technologies to build a more efficient, supportive ecosystem for digital nomads.
BACKGROUND AND RELATED WORK
While various platforms cater to DNs globally, specific solutions tailored to national programs like Malaysia's DE Rantau are emerging but often exhibit institutional inertia. For instance, the official DE Rantau mobile application (currently only accessible on the Apple App Store), developed in partnership with HostAStay, primarily focuses on booking certified accommodations and lacks comprehensive onboarding support or advanced information retrieval capabilities. Platforms like Citizen Remote offer broader tax, legal, and visa guidance, along with community features across multiple countries. However, they may lack the deep integration with specific local program details needed by DE Rantau participants. Our analysis identified a gap for a platform integrating authoritative program information with intelligent, conversational access and localized community/onboarding features.
Addressing the challenge of information retrieval from extensive documentation necessitates advancements beyond simple keyword search, instead relying on the emergent natural language processing strengths of LLMs. RAG has emerged as a powerful technique to cost-effectively enhance the accuracy and relevance of LLMs [5]. RAG architectures ground LLM responses by first retrieving relevant passages from a specified knowledge corpus before generating an answer. This approach is particularly suited for domains like nomad visa programs, where accuracy and grounding in official sources are paramount. Recent advancements have explored adaptive and self-correcting RAG methods to improve retrieval quality and response generation further [6, 7], exploring the potential for more sophisticated conversational agents. A proposed theoretical process flow is depicted in Fig. 1(a), which acts as the primary reference of this work.
The development of Pragmadic leverages these concepts synergistically with modern full-stack web architecture. We utilize LLMs, like OpenAI's API [8], for their state-of-the-art natural language understanding, generation, and embedding capabilities crucial for RAG pipelines and AI analytics. The frontend is built with Next.js, chosen for its robust support for server-side rendering, and seamless early integrations of cutting-edge client-side React features like the React Compiler, facilitating the development of complex, performant user interfaces required for mapping, chat user interfaces, and dashboards. For the backend, Supabase provides a full-fledged Backend-as-a-Service (BaaS) solution built on PostgreSQL [9]. Supabase is free and open-source software with paid managed services for authentication, storage, real-time capabilities, and crucially, its database supports vector embedding via pgvector. This technical decision streamlines the development of RAG-ready knowledge bases and embedding-related features. Pragmadic was carefully curated to integrate these technologies to create a cohesive platform specifically designed to tackle the identified limitations in existing DN support systems through intelligent information access and tailored onboarding tools.

(a) (b)
FIGURE 1. RAG Methodology Process Flow and Simplified Architectural Diagram of Pragmadic Application Layers.

METHODOLOGY AND SYSTEM ARCHITECTURE
The development of the Pragmadic platform followed a Prototyping model consisting of the phases of Communication / Requirements Gathering, Planning, Modelling, Construction, Testing, Deployment and Maintenance, and Feedback and Iteration. This software development lifecycle (SDLC) methodology was chosen for its suitability in navigating the rapidly evolving landscape of LLM capabilities and accommodating emergent user requirements identified through iterative feedback. This approach allows flexibility and is further accelerated with rapid development cycles enabled via utilizing a Supabase-managed backend instance and Vercel’s rich developer experience to streamline the deployment and CI/CD process with GitHub integration. Adopting Supabase and Vercel for deployment is essential for efficiently iterating and updating AI features.
Overall System Architecture
Pragmadic employs modern full-stack architecture, designed for scalability and maintainability. The key layers are depicted in Fig. 1(b):
• Frontend: Developed using Next.js 14 and React by adopting the newly introduced React Server Components for server-side rendering and options for performance optimization. The user interface utilizes Shadcn UI based on Radix UI for accessible and composable components, Framer Motion for animations, and MapboxGL (via react-map-gl) for interactive mapping features. Client-side state management and data fetching are handled using TanStack Query (React Query) for caching and synchronization.
• Backend: Powered by Supabase, providing a PostgreSQL database, user authentication (handling OAuth, magic links, email/password, role-based access control), object storage for documents and user uploads, real-time subscriptions, and serverless Edge Functions. The pgvector extension is utilized for enabling efficient similarity searches on text embeddings. Drizzle ORM is used for type-safe database interactions and migrations.
• AI Layer: Integrates LLMs primarily from the leading providers (OpenAI, Anthropic, Gemini, Ollama) like the OpenAI APIs (e.g., GPT-4o, text-embedding-3-small). The Vercel AI SDK serves as a crucial abstraction layer, simplifying the implementation of chat management, conversational interfaces, RAG pipelines, and tool-calling functionalities. This SDK manages streaming responses, client-server state synchronization for AI interactions, and provides UI hooks (useChat, useCompletion).
• Deployment: The application is deployed on Vercel to utilize its seamless integration with Next.js, global edge network, serverless functions for API routes, automatic CI/CD pipelines linked to GitHub, and managed infrastructure features. Supabase’s managed instance is also utilized in the interests of resource constraints.
RAG Answer Engine Implementation
The core of Pragmadic's information retrieval capability lies in its RAG implementation, designed to provide accurate answers grounded in official DE Rantau program information. Figure 2(a) shows an answer engine response based on selected documents across various categories. RAG overall is a cost-effective alternative to the expensive fine-tuning process of state-of-the-art foundational models. Additionally, via Ollama, open-source LLMs with their tradeoffs and strengths can easily be grounded in context as models continue to be more accessible and competent. The process involves several key stages that are based on the application of the theoretical research background:
• Knowledge Base Creation: Authorized administrators (through RBAC) utilize a dedicated interface within Pragmadic to upload relevant documents (PDF) pertinent to the DE Rantau program. These documents are stored securely in Supabase Storage.
• Document Processing Pipeline: A server action triggers an asynchronous processing pipeline upon upload. Documents are parsed (using edge-compatible libraries like unpdf), and the extracted text is segmented into smaller, semantically meaningful chunks using a RecursiveCharacterTextSplitter. Each chunk is then converted into a vector embedding using OpenAI's text-embedding-3-small model. These embeddings and the corresponding text chunks and metadata (source document ID, page number) are stored in a dedicated document_chunks table within the database, indexed using pgvector for efficient querying.
• Retrieval: When a user submits a query via the chat interface, the query text is embedded using the exact dimensions. A similarity search (specifically, cosine similarity) is performed against the document_chunks vector store to retrieve the top-K most relevant chunks based on semantic closeness to the user's query. This retrieval process is often enhanced by middleware (ragMiddleware), which may perform steps like query rewriting or hypothetical answer generation to improve retrieval relevance as grounded in theoretical research.
• Generation: The retrieved text chunks are formatted and appended as context to the original user query. This augmented prompt is then sent to an LLM (e.g., GPT-4o) via the Vercel AI SDK's API Next.js endpoint (/api/chat). The SDK handles the interaction with the LLM API, streams the generated response back to the user interface, and manages the conversational state using hooks like useChat. This ensures the retrieved official information contextually enriches the final answer.
AI-Driven Analytics Implementation

(a) (b)
FIGURE 2. The implementation of RAG Answer Engine and AI-Driven Analytics for DE Rantau Hub Owners

For DE Rantau Hub partners, Pragmadic offers an analytics dashboard enhanced with AI capabilities to provide deeper insights into hub activity and member engagement.
• Data Aggregation: The system collects data from user interactions within hubs, including membership changes, event participation rates, review submissions, and general activity metrics. This data is stored in Supabase.
• LLM Tool Calling: The analytics chat interface allows hub owners to pose natural language queries about their hub's performance (e.g., "Show me member demographics," "Analyze recent review sentiment"). These queries are processed by an LLM configured with specific "tools" using the AI SDK's tool-calling features.
• Tool Definition and Execution: Predefined tools (e.g., memberStatsTool, eventStatsTool, reviewAnalysisTool) are implemented as server-side functions. Each tool has a defined schema (using Zod) specifying its expected input parameters. When the LLM determines a tool should be called based on the user's query, the AI SDK facilitates invoking the corresponding backend function with the extracted parameters. These functions execute complex Drizzle ORM queries against the Supabase database to fetch, aggregate, and process the required analytics data.
• Insight Generation and Visualization: The executed tool(s) results are returned to the LLM. The LLM then synthesizes this structured data into a natural language summary or directly provides the formatted data needed for visualization. The AI SDK streams this final response back to the analytics chat interface, where insights are displayed textually, and structured data is used to render charts (using Recharts via Shadcn UI) directly within the chat or on the main dashboard. This allows hub owners to interactively explore or get suggestions with their hub data through conversation.
• This methodology combines rapid prototyping with a robust, layered architecture, leveraging modern BaaS and AI SDKs to implement complex features like RAG and LLM agent-driven analytics efficiently.
IMPLEMENTATION AND RESULTS
This section highlights the key implemented features in a prototype deployed on Vercel with a remote Supabase project instance, focusing on the RAG Answer Engine and AI-Driven Analytics. It also summarizes the evaluations.
RAG Answer Engine Functionality and Evaluation
The RAG Answer Engine provides users a conversational interface to query information about the DE Rantau program. Users can select specific documents from the knowledge base, managed by administrators via the file management interface, to scope their queries by categories and/or ask general questions. The system supports multi-turn conversations, maintains context, and allows users to upload images for additional context if needed. Responses are streamed to the UI, providing real-time feedback and an enhanced user interface and user experience.
Black box testing confirmed the core functionality of the RAG module. The achievements include:
• Successful Retrieval: The system correctly identified and retrieved relevant text chunks from the Supabase vector store based on user query embeddings.
• Contextual Generation: LLM responses were successfully grounded in the retrieved context, providing answers relevant to DE Rantau specifics contained within the knowledge base documents.
• Interface Functionality: Document selection, model switching (between different LLM providers like OpenAI), chat history management, and multi-modal input uploads operated as expected.
• Basic Error Handling: The system demonstrated basic handling for empty queries and invalid file types, providing appropriate user feedback.
AI-Driven Analytics Functionality and Evaluation
The AI-Driven Analytics module provides hub owners with a standard dashboard and a conversational chat interface for exploring hub data. The dashboard visualizes key metrics such as member role distribution and growth trends using interactive charts (e.g., pie charts, line graphs) rendered with Recharts.
The analytics chat interface allows owners to query their data using natural language. The LLM, facilitated by the Vercel AI SDK's tool-calling mechanism, interprets these queries and invokes appropriate backend tools (e.g., memberStatsTool, reviewAnalysisTool). These tools query the database, process the data, and return structured results and/or summaries to the LLM, presenting insights or generating visualizations within the chat interface. Animated prompt suggestions guide users towards effective queries.
Integration testing focused on the analytics data pipeline and tool-calling functionality. Key findings include:
• Data Flow Integrity: User actions within hubs (e.g., new member joining, event participation) correctly triggered updates that are reflected in the analytics database and subsequently visualized on the dashboard.
• Chart Rendering: Visualization components accurately rendered the processed data fetched from Supabase.
• Tool Calling Efficacy: The LLM successfully identified user intent from natural language queries, invoked the correct backend analytics tools with appropriate parameters, and received structured data back. The tools correctly executed database queries and performed necessary aggregations.
• Chat Integration: The analytics chat successfully displayed both natural language summaries generated by the LLM based on the tool results and rendered charts based on the structured data returned by the tools.
Security Considerations
Preliminary security testing focused on foundational web security principles and LLM-specific risks as recommended by OWASP [10]. Basic rate limiting was implemented on key API endpoints, particularly the chat API, using Upstash to mitigate simple DoS or abuse patterns. The RAG system's inherent safety and security benefits stem from grounding responses in a controlled knowledge base, reducing hallucination risks in addition to the intrinsic model safety and security properties of commercial LLM APIs. Techniques like multi-step adaptive and corrective RAG processing were implemented from theoretical concepts to enhance accuracy and potentially act as guardrails. Role-based access control, managed via Supabase Auth and custom JWT claims, restricts access to sensitive functions like knowledge base management and analytics tools. While comprehensive LLM security testing (e.g., advanced prompt injection, model DoS) was beyond the scope of this initial implementation, these foundational measures provide a baseline level of security for the integrated system.
DISCUSSION
The development of Pragmadic represents a minimum-viable-product of advanced AI techniques like RAG and LLM-driven analytics applied to a platform supporting digital nomads. The prototype successfully addresses the core problem of information fragmentation within the DE Rantau program by providing a conversational, context-aware answer engine grounded in knowledge bases. Furthermore, the AI analytics tools offer a novel approach to extracting valuable, accessible insights for local hub partners, moving beyond traditional dashboards.
However, several limitations warrant discussion. The platform's current scope is geographically limited to Penang and primarily focused on the DE Rantau program; broader applicability would require scalability and expansion of the knowledge base and potential localization. The reliance on commercial LLM APIs (e.g., OpenAI) introduces operational costs and dependencies, although the architecture allows for potential future integration of open-source models. The effectiveness of the RAG is inherently tied to the quality and completeness of the ingested documents, and while testing showed functional retrieval, ensuring consistent first-party verified accuracy and handling of edge cases requires ongoing refinement and evaluation. The initial evaluation scope may be limited, necessitating larger-scale user studies to assess usability, user satisfaction, and overall real-world impact. Foundational security measures also require further evaluation against sophisticated LLM-specific attacks.
Despite these limitations, Pragmadic serves as a proof-of-concept for leveraging emerging technologies for sustainable development in the context of digital nomadism. The platform facilitates smoother integration of skilled professionals with tools for local ecosystem partners. This, in turn, can contribute to knowledge transfer, local economic stimulation, and the overall sustainable growth of regional digital economies like Penang's, aligning with DE Rantau's objectives.
CONCLUSION
This paper introduces Pragmadic, a web platform designed to enhance the digital nomad experience in Penang, Malaysia, by addressing critical information access and integration challenges within the DE Rantau program. We presented the implementation of a RAG-integrated answer engine and AI-driven analytics, leveraging LLMs and modern web technologies (Next.js, Supabase, Drizzle ORM, Vercel AI SDK). The initial evaluation confirmed these AI components' feasibility and core functionality in providing grounded information retrieval and interactive data insights. Pragmadic offers a pathway to support the sustainable development of local digital economies through improved resource accessibility and integration tools for the growing digital nomad community. Future work should focus on greater research into external non-technical factors, conducting comprehensive user validation studies, and exploring open-source LLM solutions to enhance decentralization, scalability, and accessibility.
REFERENCES

1. J. Bednorz, Annals of Tourism Research 105, 103715 (2024).
2. Malaysia Digital Economy Corporation, "De Rantau Pass: Frequently Asked Questions (FAQ)" (MDEC, Putrajaya, 2024).
3. M. Aziz, "Insight: Transforming Malaysia into ASEAN’s Digital Nomad epicentre," The Edge Malaysia (13 November 2023).
4. J. Boluda Chova and K. T. von Ehrlich-Treuenstätt, "Nomadism without borders: Exploring connections in digital nomad destinations: An ethnographic multiple-case study in Malaysia & Colombia," Master's thesis, Linnaeus University, 2023.
5. P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler, M. Lewis, W. T. Yih, T. Rocktäschel, and S. Riedel, in Advances in Neural Information Processing Systems 33, edited by H. Larochelle et al. (Curran Associates, Inc., 2020), pp. 9459–9474.
6. S. Jeong, J. Baek, S. Cho, S. J. Hwang, and J. C. Park, arXiv:2403.14403 [cs.CL] (2024).
7. S. Q. Yan, J. C. Gu, Y. Zhu, and Z. H. Ling, arXiv:2401.15884 [cs.CL] (2024).
8. OpenAI, "OpenAI API Reference," OpenAI Documentation (n.d.), https://platform.openai.com/docs/api-reference/introduction.
9. Supabase, "Supabase Architecture," Supabase Documentation (n.d.), https://supabase.com/docs/guides/getting-started/architecture.
10. OWASP, "LLM AI Cybersecurity & Governance Checklist" (OWASP Foundation, 2025), https://genai.owasp.org/resource/owasp-top-10-for-llm-applications-2025.
